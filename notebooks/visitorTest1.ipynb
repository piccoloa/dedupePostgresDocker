{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "This is a setup script for mysql_example.  It downloads a zip file of\n",
    "Illinois campaign contributions and loads them in t aMySQL database\n",
    "named 'contributions'.\n",
    "\n",
    "__Note:__ You will need to run this script first before execuing\n",
    "[mysql_example.py](http://datamade.github.com/dedupe-examples/docs/mysql_example.html).\n",
    "\n",
    "Tables created:\n",
    "* raw_table - raw import of entire CSV file\n",
    "* donors - all distinct donors based on name and address\n",
    "* recipients - all distinct campaign contribution recipients\n",
    "* contributions - contribution amounts tied to donor and recipients tables\n",
    "\"\"\"\n",
    "import csv\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "import dj_database_url\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import unidecode\n",
    "import requests\n",
    "\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "\n",
    "##\n",
    "## ***Always be logging***\n",
    "##\n",
    "import traceback\n",
    "import logging\n",
    "from logging.handlers import RotatingFileHandler\n",
    "\n",
    "# Logging defaults - basic config will log to stdout, then we'll add a log-to-file handler\n",
    "# Allow log override from environ variable\n",
    "FILE_LOG_FORMAT = \"%(asctime)s %(levelname)s %(module)s:%(lineno)d %(message)s\"\n",
    "#CONSOLE_LOG_FORMAT = \"%(levelname)s %(module)s:%(lineno)d %(message)s\"\n",
    "CONSOLE_LOG_FORMAT = FILE_LOG_FORMAT\n",
    "LOG_FILENAME = 'testVisitor.log'\n",
    "\n",
    "LOG_LEVEL = os.getenv('LOG_LEVEL', logging.INFO)\n",
    "if LOG_LEVEL == 'debug':\n",
    "    LOG_LEVEL=logging.DEBUG\n",
    "\n",
    "# setup for console\n",
    "logging.basicConfig(level=LOG_LEVEL, format=CONSOLE_LOG_FORMAT)\n",
    "logger = logging.getLogger('')\n",
    "\n",
    "# setup for file\n",
    "log_file_handler = RotatingFileHandler(LOG_FILENAME, maxBytes=20971520, backupCount=5)\n",
    "log_file_handler.setFormatter(logging.Formatter(FILE_LOG_FORMAT))\n",
    "logger.addHandler(log_file_handler)\n",
    "##\n",
    "##\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(url,fname):\n",
    "    \"\"\"\n",
    "    Download the dataset from the webpage.\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    with open(fname, 'w') as f:\n",
    "        f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATAURL = \"https://open.whitehouse.gov/api/views/p86s-ychb/rows.csv?accessType=DOWNLOAD\"\n",
    "DATAURL = \"open.obamawhitehouse.archives.gov/sites/default/files/White_House_Visitor_Records_Requests.csv?\"\n",
    "#http://open.obamawhitehouse.archives.gov/sites/default/files/White_House_Visitor_Records_Requests.csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Illinois-campaign-contributions.csv\r\n",
      "Illinois-campaign-contributions.txt\r\n",
      "Illinois-campaign-contributions.txt.zip\r\n",
      "\u001b[0m\u001b[01;34m__MACOSX\u001b[0m/\r\n",
      "small_White_House_test.csv\r\n",
      "testVisitor.log\r\n",
      "Untitled.ipynb\r\n",
      "visitorTest1.ipynb\r\n",
      "White_House_Visitor_Records_Requests.csv\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ORIGFILE = \"fixtures/whitehouse-visitors.csv\"\n",
    "ORIGFILE = \"small_White_House_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getData(DATAURL,ORIGFILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "takes the csv data in as input, parses the datetime fields we’re interested in (‘lastname’,’firstname’,’uin’,’apptmade’,’apptstart’,’apptend’, ‘meeting_loc’.), and outputs a database table that retains the desired columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-13 17:04:29,815 INFO <ipython-input-12-924a8d4095d1>:9 database config loaded...\n",
      "2018-08-13 17:04:29,823 INFO <ipython-input-12-924a8d4095d1>:11 checking if database exists...\n"
     ]
    }
   ],
   "source": [
    "db_conf = dj_database_url.config()\n",
    "\n",
    "if not db_conf:\n",
    "    raise Exception(\n",
    "        'set DATABASE_URL environment variable with your connection, e.g. '\n",
    "        'export DATABASE_URL=postgres://user:password@host/mydatabase'\n",
    "    )\n",
    "else:\n",
    "    logger.info('database config loaded...')\n",
    "\n",
    "logger.info('checking if database exists...')\n",
    "conn = psycopg2.connect(user=db_conf['USER'],\n",
    "                        password=db_conf['PASSWORD'],\n",
    "                        host=db_conf['HOST'],\n",
    "                        port=db_conf['PORT'])\n",
    "\n",
    "# must set isolation level otherwise can't create database\n",
    "conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-13 17:06:05,641 INFO <ipython-input-13-839b165f611e>:10 DB already exists, lets continue...\n",
      "2018-08-13 17:06:05,643 INFO <ipython-input-13-839b165f611e>:12 re-connecting specifically to database...\n"
     ]
    }
   ],
   "source": [
    "c = conn.cursor()\n",
    "c.execute(f\"SELECT COUNT(*) = 0 FROM pg_catalog.pg_database WHERE datname = '{db_conf['NAME']}'\")\n",
    "not_exists_row = c.fetchone()\n",
    "not_exists = not_exists_row[0]\n",
    "if not_exists:\n",
    "    c.execute(f\"CREATE DATABASE {db_conf['NAME']}\")\n",
    "    conn.commit()\n",
    "    logger.info('DB didnt exist, now it does...')\n",
    "else:\n",
    "    logger.info('DB already exists, lets continue...')\n",
    "\n",
    "logger.info('re-connecting specifically to database...')\n",
    "conn = psycopg2.connect(database=db_conf['NAME'],\n",
    "                        user=db_conf['USER'],\n",
    "                        password=db_conf['PASSWORD'],\n",
    "                        host=db_conf['HOST'],\n",
    "                        port=db_conf['PORT'])\n",
    "\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cleaned up CSV version of file with consistent row lengths.\n",
    "# Postgres COPY doesn't handle \"ragged\" files very well\n",
    "if not os.path.exists(ORIGFILE):\n",
    "    logger.info('converting tab-delimited raw file to csv...')\n",
    "    with open(contributions_txt_file, 'rU') as txt_file, \\\n",
    "            open(contributions_csv_file, 'w') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file, quoting=csv.QUOTE_ALL)\n",
    "        for line in txt_file:\n",
    "            if not all(ord(c) < 128 for c in line):\n",
    "                line = unidecode.unidecode(line)\n",
    "            row = line.rstrip('\\t\\r\\n').split('\\t')\n",
    "            if len(row) != 29:\n",
    "                logger.info('skipping bad row (length %s, expected 29):' % len(row))\n",
    "                logger.info(row)\n",
    "                continue\n",
    "            csv_writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dateParseSQL(nfile):\n",
    "    c.execute('''CREATE TABLE IF NOT EXISTS visitors_er\n",
    "                  (visitor_id SERIAL PRIMARY KEY,\n",
    "                  lastname    varchar,\n",
    "                  firstname   varchar,\n",
    "                  uin         varchar,\n",
    "                  apptmade    varchar,\n",
    "                  apptstart   varchar,\n",
    "                  apptend     varchar,\n",
    "                  meeting_loc varchar);''')\n",
    "    conn.commit()\n",
    "    with open(nfile, 'rU') as infile:\n",
    "        reader = csv.reader(infile, delimiter=',')\n",
    "        next(reader, None)\n",
    "        for row in reader:\n",
    "            for field in DATEFIELDS:\n",
    "                if row[field] != '':\n",
    "                    try:\n",
    "                        dt = parser.parse(row[field])\n",
    "                        row[field] = dt.toordinal()  # We also tried dt.isoformat()\n",
    "                    except:\n",
    "                        continue\n",
    "            sql = \"INSERT INTO visitors_er(lastname,firstname,uin,apptmade,apptstart,apptend,meeting_loc) \\\n",
    "                   VALUES (%s,%s,%s,%s,%s,%s,%s)\"\n",
    "            cur.execute(sql, (row[0],row[1],row[3],row[10],row[11],row[12],row[21],))\n",
    "            conn.commit()\n",
    "    print (\"All done!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:12: DeprecationWarning: 'U' mode is deprecated\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'DATEFIELDS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-d7791a5ba3ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdateParseSQL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mORIGFILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-70f944de688d>\u001b[0m in \u001b[0;36mdateParseSQL\u001b[0;34m(nfile)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mDATEFIELDS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DATEFIELDS' is not defined"
     ]
    }
   ],
   "source": [
    "dateParseSQL(ORIGFILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://open.obamawhitehouse.archives.gov/sites/default/files/White_House_Visitor_Records_Requests.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Lets get down to business\n",
    "\n",
    "_file = 'Illinois-campaign-contributions'\n",
    "contributions_zip_file = _file + '.txt.zip'\n",
    "contributions_txt_file = _file + '.txt'\n",
    "contributions_csv_file = _file + '.csv'\n",
    "\n",
    "if not os.path.exists(contributions_zip_file):\n",
    "    logger.info('downloading', contributions_zip_file, '(~60mb) ...')\n",
    "    u = requests.get(\n",
    "        'https://s3.amazonaws.com/dedupe-data/Illinois-campaign-contributions.txt.zip')\n",
    "    localFile = open(contributions_zip_file, 'wb')\n",
    "    localFile.write(u.content)\n",
    "    localFile.close()\n",
    "\n",
    "if not os.path.exists(contributions_txt_file):\n",
    "    zip_file = zipfile.ZipFile(contributions_zip_file, 'r')\n",
    "    logger.info('extracting %s' % contributions_zip_file)\n",
    "    zip_file_contents = zip_file.namelist()\n",
    "    for f in zip_file_contents:\n",
    "        if ('.txt' in f):\n",
    "            zip_file.extract(f)\n",
    "    zip_file.close()\n",
    "\n",
    "\n",
    "\n",
    "########\n",
    "\n",
    "\n",
    "\n",
    "logger.info('loading intarray extension...')\n",
    "try:\n",
    "    c.execute(f\"CREATE EXTENSION intarray\")\n",
    "    conn.commit()\n",
    "except:\n",
    "    logger.info('extension already loaded')\n",
    "    logger.debug('Full stack trace\\n{}'.traceback.format_exc())\n",
    "    pass\n",
    "\n",
    "logger.info(\"re-creating any tables (if they exist)...\")\n",
    "c.execute(\"DROP TABLE IF EXISTS raw_table\")\n",
    "c.execute(\"DROP TABLE IF EXISTS donors\")\n",
    "c.execute(\"DROP TABLE IF EXISTS recipients\")\n",
    "c.execute(\"DROP TABLE IF EXISTS contributions\")\n",
    "c.execute(\"DROP TABLE IF EXISTS processed_donors\")\n",
    "\n",
    "c.execute(\"CREATE TABLE raw_table \"\n",
    "          \"(reciept_id INT, last_name VARCHAR(70), first_name VARCHAR(35), \"\n",
    "          \" address_1 VARCHAR(35), address_2 VARCHAR(36), city VARCHAR(20), \"\n",
    "          \" state VARCHAR(15), zip VARCHAR(11), report_type VARCHAR(24), \"\n",
    "          \" date_recieved VARCHAR(10), loan_amount VARCHAR(12), \"\n",
    "          \" amount VARCHAR(23), receipt_type VARCHAR(23), \"\n",
    "          \" employer VARCHAR(70), occupation VARCHAR(40), \"\n",
    "          \" vendor_last_name VARCHAR(70), vendor_first_name VARCHAR(20), \"\n",
    "          \" vendor_address_1 VARCHAR(35), vendor_address_2 VARCHAR(31), \"\n",
    "          \" vendor_city VARCHAR(20), vendor_state VARCHAR(10), \"\n",
    "          \" vendor_zip VARCHAR(10), description VARCHAR(90), \"\n",
    "          \" election_type VARCHAR(10), election_year VARCHAR(10), \"\n",
    "          \" report_period_begin VARCHAR(10), report_period_end VARCHAR(33), \"\n",
    "          \" committee_name VARCHAR(70), committee_id VARCHAR(37))\")\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "logger.info('importing raw data from csv...')\n",
    "with open(contributions_csv_file, 'rU') as csv_file:\n",
    "    c.copy_expert(\"COPY raw_table \"\n",
    "                  \"(reciept_id, last_name, first_name, \"\n",
    "                  \" address_1, address_2, city, state, \"\n",
    "                  \" zip, report_type, date_recieved, \"\n",
    "                  \" loan_amount, amount, receipt_type, \"\n",
    "                  \" employer, occupation, vendor_last_name, \"\n",
    "                  \" vendor_first_name, vendor_address_1, \"\n",
    "                  \" vendor_address_2, vendor_city, vendor_state, \"\n",
    "                  \" vendor_zip, description, election_type, \"\n",
    "                  \" election_year, \"\n",
    "                  \" report_period_begin, report_period_end, \"\n",
    "                  \" committee_name, committee_id) \"\n",
    "                  \"FROM STDIN CSV HEADER\", csv_file)\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "logger.info('creating donors table...')\n",
    "c.execute(\"CREATE TABLE donors \"\n",
    "          \"(donor_id SERIAL PRIMARY KEY, \"\n",
    "          \" last_name VARCHAR(70), first_name VARCHAR(35), \"\n",
    "          \" address_1 VARCHAR(35), address_2 VARCHAR(36), \"\n",
    "          \" city VARCHAR(20), state VARCHAR(15), \"\n",
    "          \" zip VARCHAR(11), employer VARCHAR(70), \"\n",
    "          \" occupation VARCHAR(40))\")\n",
    "conn.commit()\n",
    "\n",
    "logger.info('populating donors table...')\n",
    "c.execute(\"INSERT INTO donors \"\n",
    "          \"(first_name, last_name, address_1, \"\n",
    "          \" address_2, city, state, zip, employer, occupation) \"\n",
    "          \"SELECT DISTINCT \"\n",
    "          \"LOWER(TRIM(first_name)), LOWER(TRIM(last_name)), \"\n",
    "          \"LOWER(TRIM(address_1)), LOWER(TRIM(address_2)), \"\n",
    "          \"LOWER(TRIM(city)), LOWER(TRIM(state)), LOWER(TRIM(zip)), \"\n",
    "          \"LOWER(TRIM(employer)), LOWER(TRIM(occupation)) \"\n",
    "          \"FROM raw_table\")\n",
    "conn.commit()\n",
    "\n",
    "logger.info('creating indexes on donors table...')\n",
    "c.execute(\"CREATE INDEX donors_donor_info ON donors \"\n",
    "          \"(last_name, first_name, address_1, address_2, city, \"\n",
    "          \" state, zip)\")\n",
    "conn.commit()\n",
    "\n",
    "logger.info('creating recipients table...')\n",
    "c.execute(\"CREATE TABLE recipients \"\n",
    "          \"(recipient_id SERIAL PRIMARY KEY, name VARCHAR(70))\")\n",
    "conn.commit()\n",
    "\n",
    "logger.info('populating recipients table...')\n",
    "c.execute(\"INSERT INTO recipients \"\n",
    "          \"SELECT DISTINCT CAST(committee_id AS INTEGER), \"\n",
    "          \"committee_name FROM raw_table\")\n",
    "conn.commit()\n",
    "\n",
    "logger.info('creating contributions table...')\n",
    "c.execute(\"CREATE TABLE contributions \"\n",
    "          \"(contribution_id INT, donor_id INT, recipient_id INT, \"\n",
    "          \" report_type VARCHAR(24), date_recieved DATE, \"\n",
    "          \" loan_amount VARCHAR(12), amount VARCHAR(23), \"\n",
    "          \" receipt_type VARCHAR(23), \"\n",
    "          \" vendor_last_name VARCHAR(70), \"\n",
    "          \" vendor_first_name VARCHAR(20), \"\n",
    "          \" vendor_address_1 VARCHAR(35), vendor_address_2 VARCHAR(31), \"\n",
    "          \" vendor_city VARCHAR(20), vendor_state VARCHAR(10), \"\n",
    "          \" vendor_zip VARCHAR(10), description VARCHAR(90), \"\n",
    "          \" election_type VARCHAR(10), election_year VARCHAR(10), \"\n",
    "          \" report_period_begin DATE, report_period_end DATE)\")\n",
    "conn.commit()\n",
    "\n",
    "logger.info('populating contributions table...')\n",
    "c.execute(\"INSERT INTO contributions \"\n",
    "          \"SELECT reciept_id, donors.donor_id, CAST(committee_id AS INTEGER), \"\n",
    "          \" report_type, TO_DATE(TRIM(date_recieved), 'MM/DD/YYYY'), \"\n",
    "          \" loan_amount, amount, \"\n",
    "          \" receipt_type, vendor_last_name , \"\n",
    "          \" vendor_first_name, vendor_address_1,\"\n",
    "          \" vendor_address_2, \"\n",
    "          \" vendor_city, vendor_state, vendor_zip,\"\n",
    "          \" description, \"\n",
    "          \" election_type, election_year, \"\n",
    "          \" TO_DATE(TRIM(report_period_begin), 'MM/DD/YYYY'), \"\n",
    "          \" TO_DATE(TRIM(report_period_end), 'MM/DD/YYYY') \"\n",
    "          \"FROM raw_table JOIN donors ON \"\n",
    "          \"donors.first_name = LOWER(TRIM(raw_table.first_name)) AND \"\n",
    "          \"donors.last_name = LOWER(TRIM(raw_table.last_name)) AND \"\n",
    "          \"donors.address_1 = LOWER(TRIM(raw_table.address_1)) AND \"\n",
    "          \"donors.address_2 = LOWER(TRIM(raw_table.address_2)) AND \"\n",
    "          \"donors.city = LOWER(TRIM(raw_table.city)) AND \"\n",
    "          \"donors.state = LOWER(TRIM(raw_table.state)) AND \"\n",
    "          \"donors.employer = LOWER(TRIM(raw_table.employer)) AND \"\n",
    "          \"donors.occupation = LOWER(TRIM(raw_table.occupation)) AND \"\n",
    "          \"donors.zip = LOWER(TRIM(raw_table.zip))\")\n",
    "conn.commit()\n",
    "\n",
    "logger.info('creating indexes on contributions...')\n",
    "c.execute(\"ALTER TABLE contributions ADD PRIMARY KEY(contribution_id)\")\n",
    "c.execute(\"CREATE INDEX donor_idx ON contributions (donor_id)\")\n",
    "c.execute(\"CREATE INDEX recipient_idx ON contributions (recipient_id)\")\n",
    "conn.commit()\n",
    "\n",
    "logger.info('nullifying empty strings in donors...')\n",
    "c.execute(\n",
    "    \"UPDATE donors \"\n",
    "    \"SET \"\n",
    "    \"first_name = CASE first_name WHEN '' THEN NULL ELSE first_name END, \"\n",
    "    \"last_name = CASE last_name WHEN '' THEN NULL ELSE last_name END, \"\n",
    "    \"address_1 = CASE address_1 WHEN '' THEN NULL ELSE address_1 END, \"\n",
    "    \"address_2 = CASE address_2 WHEN '' THEN NULL ELSE address_2 END, \"\n",
    "    \"city = CASE city WHEN '' THEN NULL ELSE city END, \"\n",
    "    \"state = CASE state WHEN '' THEN NULL ELSE state END, \"\n",
    "    \"employer = CASE employer WHEN '' THEN NULL ELSE employer END, \"\n",
    "    \"occupation = CASE occupation WHEN '' THEN NULL ELSE occupation END, \"\n",
    "    \"zip = CASE zip WHEN '' THEN NULL ELSE zip END\"\n",
    ")\n",
    "conn.commit()\n",
    "\n",
    "logger.info('creating processed_donors...')\n",
    "c.execute(\"CREATE TABLE processed_donors AS \"\n",
    "          \"(SELECT donor_id, \"\n",
    "          \" LOWER(city) AS city, \"\n",
    "          \" CASE WHEN (first_name IS NULL AND last_name IS NULL) \"\n",
    "          \"      THEN NULL \"\n",
    "          \"      ELSE LOWER(CONCAT_WS(' ', first_name, last_name)) \"\n",
    "          \" END AS name, \" \n",
    "          \" LOWER(zip) AS zip, \"\n",
    "          \" LOWER(state) AS state, \"\n",
    "          \" CASE WHEN (address_1 IS NULL AND address_2 IS NULL) \"\n",
    "          \"      THEN NULL \"\n",
    "          \"      ELSE LOWER(CONCAT_WS(' ', address_1, address_2)) \"\n",
    "          \" END AS address, \" \n",
    "          \" LOWER(occupation) AS occupation, \"\n",
    "          \" LOWER(employer) AS employer, \"\n",
    "          \" CAST((first_name IS NULL) AS INTEGER) AS person \"\n",
    "          \" FROM donors)\")\n",
    "\n",
    "logger.info('creating index on processed_donors...')\n",
    "c.execute(\"CREATE INDEX processed_donor_idx ON processed_donors (donor_id)\")\n",
    "conn.commit()\n",
    "\n",
    "c.close()\n",
    "conn.close()\n",
    "\n",
    "logger.info('ETL job completed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "This is a setup script for mysql_example.  It downloads a zip file of\n",
    "Illinois campaign contributions and loads them in t aMySQL database\n",
    "named 'contributions'.\n",
    "\n",
    "__Note:__ You will need to run this script first before execuing\n",
    "[mysql_example.py](http://datamade.github.com/dedupe-examples/docs/mysql_example.html).\n",
    "\n",
    "Tables created:\n",
    "* raw_table - raw import of entire CSV file\n",
    "* donors - all distinct donors based on name and address\n",
    "* recipients - all distinct campaign contribution recipients\n",
    "* contributions - contribution amounts tied to donor and recipients tables\n",
    "\"\"\"\n",
    "import csv\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "import dj_database_url\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import unidecode\n",
    "import requests\n",
    "\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "\n",
    "##\n",
    "## ***Always be logging***\n",
    "##\n",
    "import traceback\n",
    "import logging\n",
    "from logging.handlers import RotatingFileHandler\n",
    "\n",
    "# Logging defaults - basic config will log to stdout, then we'll add a log-to-file handler\n",
    "# Allow log override from environ variable\n",
    "FILE_LOG_FORMAT = \"%(asctime)s %(levelname)s %(module)s:%(lineno)d %(message)s\"\n",
    "#CONSOLE_LOG_FORMAT = \"%(levelname)s %(module)s:%(lineno)d %(message)s\"\n",
    "CONSOLE_LOG_FORMAT = FILE_LOG_FORMAT\n",
    "LOG_FILENAME = 'testVistor.log'\n",
    "\n",
    "LOG_LEVEL = os.getenv('LOG_LEVEL', logging.INFO)\n",
    "if LOG_LEVEL == 'debug':\n",
    "    LOG_LEVEL=logging.DEBUG\n",
    "\n",
    "# setup for console\n",
    "logging.basicConfig(level=LOG_LEVEL, format=CONSOLE_LOG_FORMAT)\n",
    "logger = logging.getLogger('')\n",
    "\n",
    "# setup for file\n",
    "log_file_handler = RotatingFileHandler(LOG_FILENAME, maxBytes=20971520, backupCount=5)\n",
    "log_file_handler.setFormatter(logging.Formatter(FILE_LOG_FORMAT))\n",
    "logger.addHandler(log_file_handler)\n",
    "##\n",
    "##\n",
    "##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
